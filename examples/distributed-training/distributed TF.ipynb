{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tf_dist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tf_dist.py\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import json\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "# Scaling MNIST data from (0, 255] to (0., 1.]\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "datasets, info = tfds.load(name='mnist',\n",
    "                           with_info=True,\n",
    "                           as_supervised=True)\n",
    "\n",
    "train_datasets_unbatched = datasets['train'].map(scale).shuffle(BUFFER_SIZE)\n",
    "train_datasets = train_datasets_unbatched.batch(BATCH_SIZE)\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "      loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "NUM_WORKERS = 2\n",
    "# Here the batch size scales up by number of workers since \n",
    "# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \n",
    "# and now this becomes 128.\n",
    "GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\n",
    "train_datasets = train_datasets_unbatched.batch(GLOBAL_BATCH_SIZE)\n",
    "with strategy.scope():\n",
    "    multi_worker_model = build_and_compile_cnn_model()\n",
    "multi_worker_model.fit(x=train_datasets, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairing\n",
    "from fairing.preprocessors.base import BasePreProcessor\n",
    "from fairing.preprocessors.function import FunctionPreProcessor\n",
    "\n",
    "from fairing.builders.append.append import AppendBuilder\n",
    "from fairing.deployers.tfjob.tfjob import TfJob\n",
    "from fairing.builders.docker.docker import DockerBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = fairing.cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes.client.models.v1_resource_requirements import V1ResourceRequirements\n",
    "def add_gpu(kube_manager, pod_spec, namespace):\n",
    "    pod_spec.containers[0].resources = V1ResourceRequirements(limits={\"nvidia.com/gpu\":\"1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = BasePreProcessor(command=[\"python\",\"tf_dist.py\"],\n",
    "                                input_files=[\"tf_dist.py\", \"requirements.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building image using docker\n",
      "Docker command: ['python', 'tf_dist.py', '/app/tf_dist.py']\n",
      "Creating docker context: /tmp/fairing_context_nmtkun45\n",
      "Building docker image gcr.io/caip-dexter-bugbash/fairing-job/fairing-job:BC00C163...\n",
      "Build output: Step 1/7 : FROM tensorflow/tensorflow:2.0.0b0-gpu\n",
      "Build output: \n",
      "Build output: ---> b53afcb4b0f4\n",
      "Build output: Step 2/7 : WORKDIR /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 98b149411154\n",
      "Build output: Step 3/7 : ENV FAIRING_RUNTIME 1\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 8eaad7315849\n",
      "Build output: Step 4/7 : COPY /app//requirements.txt /app/\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 53b4fd790eb7\n",
      "Build output: Step 5/7 : RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "Build output: \n",
      "Build output: ---> Using cache\n",
      "Build output: ---> 850752aba54f\n",
      "Build output: Step 6/7 : COPY /app/ /app/\n",
      "Build output: \n",
      "Build output: ---> e1122f3a4e3a\n",
      "Build output: Step 7/7 : CMD python tf_dist.py /app/tf_dist.py\n",
      "Build output: \n",
      "Build output: ---> Running in 2e335ec91da0\n",
      "Build output: ---> 43bb605a46ff\n",
      "Push finished: {'ID': 'sha256:43bb605a46ffdd57f5c02693441c362d9c0220c8e1589030ee82c75324e4b192'}\n",
      "Build output: Successfully built 43bb605a46ff\n",
      "Build output: Successfully tagged gcr.io/caip-dexter-bugbash/fairing-job/fairing-job:BC00C163\n",
      "Publishing image gcr.io/caip-dexter-bugbash/fairing-job/fairing-job:BC00C163...\n",
      "Push output: The push refers to repository [gcr.io/caip-dexter-bugbash/fairing-job/fairing-job] None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Preparing None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Waiting None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Pushing [=========>                                         ]     512B/2.606kB\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Pushing [==================================================>]  8.192kB\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Layer already exists None\n",
      "Push output: Pushed None\n",
      "Push output: BC00C163: digest: sha256:b83699493a5c5bfebbd568939307268ba3bf791d90c580e7d3d8607014ed2f33 size: 4091 None\n",
      "Push finished: {'Tag': 'BC00C163', 'Digest': 'sha256:b83699493a5c5bfebbd568939307268ba3bf791d90c580e7d3d8607014ed2f33', 'Size': 4091}\n"
     ]
    }
   ],
   "source": [
    "builder = DockerBuilder(registry=DOCKER_REGISTRY,\n",
    "                        base_image=\"tensorflow/tensorflow:2.0.0b0-gpu\",\n",
    "                        preprocessor=preprocessor)\n",
    "builder.build()\n",
    "pod_spec = builder.generate_pod_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training job fairing-tfjob-vfpcb launched.\n",
      "Waiting for fairing-tfjob-vfpcb-worker-0 to start...\n",
      "Waiting for fairing-tfjob-vfpcb-worker-0 to start...\n",
      "Waiting for fairing-tfjob-vfpcb-worker-0 to start...\n",
      "Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-14 01:05:21.032687: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-06-14 01:05:21.087147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.088446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:05:21.089365: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:05:21.093204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:05:21.096435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:05:21.097928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:05:21.101470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:05:21.105270: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:05:21.115970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:05:21.116109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.116522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.118326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:05:21.118886: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-06-14 01:05:21.289550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.292887: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55937dc6d850 executing computations on platform CUDA. Devices:\n",
      "2019-06-14 01:05:21.292914: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2019-06-14 01:05:21.299444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-06-14 01:05:21.299553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55937dffc670 executing computations on platform Host. Devices:\n",
      "2019-06-14 01:05:21.299563: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-06-14 01:05:21.299789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.300120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:05:21.300158: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:05:21.300167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:05:21.300175: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:05:21.300183: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:05:21.300191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:05:21.300205: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:05:21.300213: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:05:21.300265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.300591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.302582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:05:21.302638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:05:21.303641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-14 01:05:21.303658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\n",
      "2019-06-14 01:05:21.303664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\n",
      "2019-06-14 01:05:21.305541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.306008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.306352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-14 01:05:21.308772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.309094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:05:21.309117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:05:21.309125: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:05:21.309132: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:05:21.309139: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:05:21.309145: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:05:21.309151: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:05:21.309159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:05:21.309217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.309543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.311703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:05:21.311816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-14 01:05:21.311828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\n",
      "2019-06-14 01:05:21.311834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\n",
      "2019-06-14 01:05:21.312086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.312455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.314276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "2019-06-14 01:05:21.317486: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:250] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> fairing-tfjob-vfpcb-worker-1.kubeflow.svc:2222, 2 -> fairing-tfjob-vfpcb-worker-2.kubeflow.svc:2222}\n",
      "2019-06-14 01:05:21.320295: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:365] Started server with target: grpc://localhost:2222\n",
      "2019-06-14 01:05:21.347140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.350575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:05:21.350635: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:05:21.350645: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:05:21.350651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:05:21.350658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:05:21.350666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:05:21.350673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:05:21.350681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:05:21.350810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.351157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.351476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:05:21.351509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-14 01:05:21.351515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\n",
      "2019-06-14 01:05:21.351520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\n",
      "2019-06-14 01:05:21.370411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.374051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:05:21.374392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0614 01:05:21.390902 140391331522368 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:GPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 1/1 [00:00<00:00,  7.44 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  7.44 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 1/1 [00:00<00:00,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:01,  6.13 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.77 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:01,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  40%|████      | 4/10 [00:00<00:00,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  50%|█████     | 5/10 [00:00<00:00,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  60%|██████    | 6/10 [00:00<00:00,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  70%|███████   | 7/10 [00:00<00:00,  6.32 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:00<00:00,  8.77 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]\n",
      "Dl Size...:  80%|████████  | 8/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  90%|█████████ | 9/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  9.18 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00,  8.84 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00,  8.84 url/s]7 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:00<00:00,  8.77 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00,  8.84 url/s]1 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00,  8.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:00<00:00,  3.51 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 10.24 MiB/s]\u001b[A\n",
      "7926 examples [00:02, 2640.66 examples/s]\n",
      "16014 examples [00:05, 3375.06 examples/s]\n",
      "23869 examples [00:07, 3162.61 examples/s]\n",
      "31385 examples [00:10, 3183.34 examples/s]\n",
      "39302 examples [00:12, 3420.83 examples/s]\n",
      "47381 examples [00:14, 3211.86 examples/s]\n",
      "55191 examples [00:17, 3153.13 examples/s]\n",
      "Shuffling...:   0%|          | 0/10 [00:00<?, ? shard/s]W0614 01:05:41.967519 140391331522368 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_datasets/core/file_format_adapter.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in\n",
      " a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and:\n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                           \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  20%|██        | 2/10 [00:00<00:00, 16.08 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                           \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  40%|████      | 4/10 [00:00<00:00, 16.41 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                           \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  60%|██████    | 6/10 [00:00<00:00, 16.64 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                           \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  80%|████████  | 8/10 [00:00<00:00, 16.68 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "                                                           \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "6209 examples [00:01, 3188.04 examples/s]                        \n",
      "Shuffling...:   0%|          | 0/1 [00:00<?, ? shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "W0614 01:28:05.905370 140391331522368 distribute_coordinator.py:825] `eval_fn` is not passed in. The `worker_fn` will be used if an \"evaluator\" task exists in the cluster.\n",
      "W0614 01:28:05.905955 140391331522368 distribute_coordinator.py:829] `eval_strategy` is not passed in. No distribution strategy will be used for evaluation.\n",
      "2019-06-14 01:28:05.912005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.912363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:28:05.912449: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:28:05.912460: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:28:05.912470: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:28:05.912479: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:28:05.912494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:28:05.912504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:28:05.912518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:28:05.912588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.913047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.913257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:28:05.913325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-14 01:28:05.913333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\n",
      "2019-06-14 01:28:05.913339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\n",
      "2019-06-14 01:28:05.913476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.915550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.915852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "W0614 01:28:05.916238 140391331522368 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:GPU:0\n",
      "2019-06-14 01:28:05.919667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.920017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:\n",
      "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-06-14 01:28:05.920064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-06-14 01:28:05.920074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:28:05.920081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-06-14 01:28:05.920089: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-06-14 01:28:05.920097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-06-14 01:28:05.920104: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-06-14 01:28:05.920112: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-06-14 01:28:05.920176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.920430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.920631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-06-14 01:28:05.920672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-14 01:28:05.920679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0\n",
      "2019-06-14 01:28:05.920684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N\n",
      "2019-06-14 01:28:05.923050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.923346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-06-14 01:28:05.923562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 14927 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
      "W0614 01:28:05.924057 140391331522368 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:worker/replica:0/task:0/device:GPU:0\n",
      "W0614 01:28:05.924550 140391331522368 distributed_training_utils.py:1094] ModelCheckpoint callback is not provided. Workers will need to restart training if any fails.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-14 01:28:06.825860: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1483] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2019-06-14 01:28:06.841210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-06-14 01:28:09.578914: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "\u001b[1mDownloading and preparing dataset mnist (11.06 MiB) to /root/tensorflow_datasets/mnist/1.0.0...\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Train on None steps\n",
      "Epoch 1/3\n",
      "      9/Unknown - 6s 779ms/step - loss: 2.2921 - accuracy: 0.146\n",
      "     16/Unknown - 7s 407ms/step - loss: 2.2909 - accuracy: 0.154\n",
      "     24/Unknown - 7s 283ms/step - loss: 2.2903 - accuracy: 0.151\n",
      "     32/Unknown - 7s 222ms/step - loss: 2.2887 - accuracy: 0.155\n",
      "     40/Unknown - 7s 184ms/step - loss: 2.2866 - accuracy: 0.162\n",
      "     48/Unknown - 8s 162ms/step - loss: 2.2847 - accuracy: 0.170\n",
      "     55/Unknown - 8s 143ms/step - loss: 2.2829 - accuracy: 0.176\n",
      "     63/Unknown - 8s 129ms/step - loss: 2.2802 - accuracy: 0.185\n",
      "     71/Unknown - 8s 118ms/step - loss: 2.2779 - accuracy: 0.193\n",
      "     79/Unknown - 9s 109ms/step - loss: 2.2755 - accuracy: 0.200\n",
      "     87/Unknown - 9s 102ms/step - loss: 2.2741 - accuracy: 0.206\n",
      "     95/Unknown - 9s 97ms/step - loss: 2.2720 - accuracy: 0.2110\n",
      "    103/Unknown - 9s 92ms/step - loss: 2.2702 - accuracy: 0.21\n",
      "    110/Unknown - 10s 88ms/step - loss: 2.2685 - accuracy: 0.223\n",
      "    118/Unknown - 10s 85ms/step - loss: 2.2668 - accuracy: 0.239\n",
      "    126/Unknown - 10s 81ms/step - loss: 2.2646 - accuracy: 0.236\n",
      "    134/Unknown - 11s 79ms/step - loss: 2.2632 - accuracy: 0.241\n",
      "    142/Unknown - 11s 76ms/step - loss: 2.2614 - accuracy: 0.247\n",
      "    149/Unknown - 11s 74ms/step - loss: 2.2596 - accuracy: 0.253\n",
      "    157/Unknown - 11s 72ms/step - loss: 2.2574 - accuracy: 0.261\n",
      "    165/Unknown - 12s 70ms/step - loss: 2.2552 - accuracy: 0.269\n",
      "    173/Unknown - 12s 69ms/step - loss: 2.2533 - accuracy: 0.274\n",
      "    181/Unknown - 12s 67ms/step - loss: 2.2517 - accuracy: 0.280\n",
      "    189/Unknown - 12s 66ms/step - loss: 2.2497 - accuracy: 0.286\n",
      "    196/Unknown - 13s 65ms/step - loss: 2.2481 - accuracy: 0.290\n",
      "    204/Unknown - 13s 64ms/step - loss: 2.2462 - accuracy: 0.296\n",
      "    212/Unknown - 13s 63ms/step - loss: 2.2443 - accuracy: 0.302\n",
      "    220/Unknown - 14s 62ms/step - loss: 2.2425 - accuracy: 0.307\n",
      "    228/Unknown - 14s 61ms/step - loss: 2.2403 - accuracy: 0.313\n",
      "    235/Unknown - 14s 60ms/step - loss: 2.2384 - accuracy: 0.318\n",
      "    243/Unknown - 14s 60ms/step - loss: 2.2361 - accuracy: 0.324\n",
      "    251/Unknown - 15s 59ms/step - loss: 2.2341 - accuracy: 0.330\n",
      "    259/Unknown - 15s 58ms/step - loss: 2.2319 - accuracy: 0.335\n",
      "    267/Unknown - 15s 57ms/step - loss: 2.2301 - accuracy: 0.340\n",
      "    274/Unknown - 16s 57ms/step - loss: 2.2282 - accuracy: 0.345\n",
      "    282/Unknown - 16s 56ms/step - loss: 2.2260 - accuracy: 0.350\n",
      "    290/Unknown - 16s 55ms/step - loss: 2.2239 - accuracy: 0.355\n",
      "    298/Unknown - 16s 55ms/step - loss: 2.2218 - accuracy: 0.3605\n",
      "    306/Unknown - 17s 54ms/step - loss: 2.2199 - accuracy: 0.365\n",
      "    314/Unknown - 17s 54ms/step - loss: 2.2178 - accuracy: 0.369\n",
      "    321/Unknown - 17s 53ms/step - loss: 2.2158 - accuracy: 0.373\n",
      "    329/Unknown - 17s 52ms/step - loss: 2.2137 - accuracy: 0.377\n",
      "    337/Unknown - 17s 52ms/step - loss: 2.2115 - accuracy: 0.380\n",
      "    345/Unknown - 18s 51ms/step - loss: 2.2092 - accuracy: 0.384\n",
      "    353/Unknown - 18s 50ms/step - loss: 2.2072 - accuracy: 0.388\n",
      "    360/Unknown - 18s 50ms/step - loss: 2.2050 - accuracy: 0.392\n",
      "    368/Unknown - 18s 49ms/step - loss: 2.2028 - accuracy: 0.395\n",
      "    376/Unknown - 18s 49ms/step - loss: 2.2006 - accuracy: 0.398\n",
      "    384/Unknown - 19s 48ms/step - loss: 2.1983 - accuracy: 0.401\n",
      "    392/Unknown - 19s 48ms/step - loss: 2.1964 - accuracy: 0.405\n",
      "    400/Unknown - 19s 47ms/step - loss: 2.1940 - accuracy: 0.408\n",
      "    407/Unknown - 19s 47ms/step - loss: 2.1914 - accuracy: 0.412\n",
      "    415/Unknown - 19s 46ms/step - loss: 2.1890 - accuracy: 0.415\n",
      "    419/Unknown - 19s 46ms/step - loss: 2.1879 - accuracy: 0.4171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fairing-tfjob-vfpcb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployer = TfJob(namespace=\"kubeflow\",\n",
    "                 pod_spec_mutators=[add_gpu],\n",
    "                 worker_count=3,\n",
    "                 chief_count=0)\n",
    "deployer.deploy(pod_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
